replicas: 1
# Use DaemonSet for logs if needed: set deploymentStrategy or use kind: DaemonSet (not shown here for brevity)
alloy:
  clustering:
    enabled: true   # enable internal clustering (needed for HA/replicas coordination)
  extraPorts:
    - name: otel-otlp-grpc    # open port for OTLP gRPC (traces)
      port: 4317
      targetPort: 4317
    - name: otel-otlp-http
      port: 4318
      targetPort: 4318
    - name: opencensus
      port: 55678
      targetPort: 55678
  configMap:
    content: |-
      logging {
        level = "info"
        format = "logfmt"
      }

      // Discover all pods and nodes in the cluster
      discovery.kubernetes "pods" {
        role = "pod"
      }
      discovery.kubernetes "nodes" {
        role = "node"
      }

      // Relabel to filter pods that have prometheus annotations for metrics scraping
      discovery.relabel "metrics" {
        targets = discovery.kubernetes.pods.targets
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_prometheus_io_port"]
          target_label  = "__meta_kubernetes_pod_container_port_number"
          action = "keepequal"         // keep pods where there's a port matching the prometheus scrape port annotation
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_container_port_number"]
          regex = ""
          action = "drop"             // drop any target that doesn't have a port (i.e., no prometheus_io_port annotation)
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_prometheus_io_path"]
          target_label  = "__metrics_path__"
          action = "replace"
          separator = ""
        }
      }

      // Metrics scrape: scrape metrics from annotated pod endpoints
      prometheus.scrape "metrics" {
        targets    = discovery.relabel.metrics.output
        scrape_interval = "30s"
        honor_labels = true
        forward_to = [ prometheus.remote_write.metrics.receiver ]
      }

      // Scrape node (kubelet/cAdvisor) metrics for all nodes
      discovery.relabel "pods_metrics" {
        targets = discovery.kubernetes.nodes.targets
        rule {
          replacement  = "kubernetes.default.svc:443"
          target_label = "__address__"
        }
        rule {
          regex         = "(.+)"
          replacement   = "/api/v1/nodes/$1/proxy/metrics/cadvisor"
          source_labels = ["__meta_kubernetes_node_name"]
          target_label  = "__metrics_path__"
        }
      }
      prometheus.scrape "pods_metrics" {
        targets      = discovery.relabel.pods_metrics.output
        job_name     = "kubelet-cadvisor"
        scheme       = "https"
        honor_labels = true
        scrape_interval = "30s"
        bearer_token_file = "/var/run/secrets/kubernetes.io/serviceaccount/token"
        tls_config {
          insecure_skip_verify = true
          server_name = "kubernetes"
        }
        forward_to = [ prometheus.remote_write.metrics.receiver ]
      }

      // Collect host OS metrics (node OS metrics via built-in exporter)
      prometheus.exporter.unix "node_os" {}
      prometheus.scrape "os_metrics" {
        targets    = prometheus.exporter.unix.node_os.targets
        scrape_interval = "30s"
        forward_to = [ prometheus.remote_write.metrics.receiver ]
      }

      // Remote write exporter for metrics â€“ sends to Grafana Mimir (Prometheus remote-write API)
      prometheus.remote_write "metrics" {
        endpoint {
          url = "http://{{ .Release.Name }}-mimir-nginx.monitoring.svc.cluster.local/api/v1/push"
        }
      }

      // Log collection: use Kubernetes integration to read pod logs
      loki.source.kubernetes "pods" {
        targets    = discovery.kubernetes.pods.targets
        forward_to = [ loki.process.batch.receiver ]
      }
      // Process logs: example pipeline to parse JSON logs and extract level
      loki.process "batch" {
        // Drop very old logs (already an hour old) - to avoid backlog on start
        stage.drop {
          older_than = "1h"
          drop_counter_reason = "too_old"
        }
        stage.json {
          expressions = { level = "level" }   // parse JSON field "level"
          // (Add other fields as needed)
        }
        stage.labels {
          values = { level = "level" }        // promote log level to a label
        }
        stage.label_drop {
          values = [ "pod", "namespace" ]     // (just an example, drop any unwanted labels)
        }
        forward_to = [ loki.write.loki.receiver ]
      }
      // Send logs to Loki
      loki.write "loki" {
        endpoint {
          url = "http://{{ .Release.Name }}-loki-ingester.monitoring.svc.cluster.local:3100/loki/api/v1/push"
        }
      }

      // Trace collection: receive spans via OpenTelemetry (OTLP) and OpenCensus
      otelcol.receiver.otlp "traces" {
        grpc {
          endpoint = "0.0.0.0:4317"
        }
        http {
          endpoint = "0.0.0.0:4318"
        }
        output { traces = [ otelcol.processor.attributes.traces.input ] }
      }
      otelcol.receiver.opencensus "traces" {
        endpoint = "0.0.0.0:55678"
        transport = "tcp"
        output { traces = [ otelcol.processor.batch.traces.input ] }
      }
      // Add a resource attribute to traces (e.g., cluster name) for identification
      otelcol.processor.attributes "traces" {
        action {
          key = "cluster_name"
          value = "homelab-cluster"
          action = "insert"
        }
        output { traces = [ otelcol.processor.batch.traces.input ] }
      }
      otelcol.processor.batch "traces" {
        timeout = "1s"
        output { traces = [ otelcol.exporter.otlp.traces.input ] }
      }
      // Export traces to Tempo (via OTLP)
      otelcol.exporter.otlp "traces" {
        client {
          endpoint = "tempo.monitoring.svc.cluster.local:4317"
          tls {
            insecure = true
            insecure_skip_verify = true
          }
        }
      }